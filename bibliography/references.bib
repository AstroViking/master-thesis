@MISC{Cowan2014-ya,
  title    = "{Self-Organized} Criticality and {Near-Criticality} in Neural
              Networks",
  author   = "Cowan, Jack D and Neuman, Jeremy and van Drongelen, Wim",
  journal  = "Criticality in Neural Systems",
  pages    = "465--484",
  year     =  2014,
  keywords = "Master thesis"
}

@INPROCEEDINGS{Divis2022-gj,
  title     = "Neural Criticality Metric for Object Detection Deep Neural
               Networks",
  booktitle = "Computer Safety, Reliability, and Security. {SAFECOMP} 2022
               Workshops",
  author    = "Divi{\v s}, V{\'a}clav and Schuster, Tobias and Hr{\'u}z, Marek",
  abstract  = "The complexity of state-of-the-art Deep Neural Network (DNN)
               architectures exacerbates the search for safety relevant metrics
               and methods that could be used for functional safety
               assessments. In this article, we investigate Neurons'
               Criticality (the ability to affect the decision process) for
               several object detection DNN architectures. As a first step, we
               introduce the Neural Criticality metric for object detection
               DNNs and set a theoretical background. Subsequently, by
               conducting experiments, we verify that removing one neuron from
               the computational graph of a DNN can have a significant
               (positive, as well as negative) influence on the prediction's
               precision (object classification and localization). Finally, we
               build statistics for each neuron from pre-trained networks on
               the COCO object detection validation dataset and examine the
               network stability for the most critical neurons in order to
               prove our metric's validity.",
  publisher = "Springer International Publishing",
  pages     = "276--288",
  year      =  2022,
  keywords  = "Master thesis"
}

@ARTICLE{Katsnelson2021-vx,
  title         = "Self-organized criticality in neural networks",
  author        = "Katsnelson, Mikhail I and Vanchurin, Vitaly and Westerhout,
                   Tom",
  abstract      = "We demonstrate, both analytically and numerically, that
                   learning dynamics of neural networks is generically
                   attracted towards a self-organized critical state. The
                   effect can be modeled with quartic interactions between
                   non-trainable variables (e.g. states of neurons) and
                   trainable variables (e.g. weight matrix). Non-trainable
                   variables are rapidly driven towards stochastic equilibrium
                   and trainable variables are slowly driven towards learning
                   equilibrium described by a scale-invariant distribution on a
                   wide range of scales. Our results suggest that the scale
                   invariance observed in many physical and biological systems
                   might be due to some kind of learning dynamics and support
                   the claim that the universe might be a neural network.",
  month         =  jul,
  year          =  2021,
  keywords      = "Master thesis",
  archivePrefix = "arXiv",
  primaryClass  = "cond-mat.stat-mech",
  eprint        = "2107.03402"
}

@ARTICLE{Chatterji2019-ix,
  title         = "The intriguing role of module criticality in the
                   generalization of deep networks",
  author        = "Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie",
  abstract      = "We study the phenomenon that some modules of deep neural
                   networks (DNNs) are more critical than others. Meaning that
                   rewinding their parameter values back to initialization,
                   while keeping other modules fixed at the trained parameters,
                   results in a large drop in the network's performance. Our
                   analysis reveals interesting properties of the loss
                   landscape which leads us to propose a complexity measure,
                   called module criticality, based on the shape of the valleys
                   that connects the initial and final values of the module
                   parameters. We formulate how generalization relates to the
                   module criticality, and show that this measure is able to
                   explain the superior generalization performance of some
                   architectures over others, whereas earlier measures fail to
                   do so.",
  month         =  dec,
  year          =  2019,
  keywords      = "Master thesis",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1912.00528"
}

@ARTICLE{Knuth1984-ih,
  title     = "Literate Programming",
  author    = "Knuth, D E",
  abstract  = "Abstract. The author and his associates have been experimenting
               for the past several years with a programming language and
               documentation system called WEB. This",
  journal   = "Comput. J.",
  publisher = "Oxford Academic",
  volume    =  27,
  number    =  2,
  pages     = "97--111",
  month     =  jan,
  year      =  1984,
  keywords  = "Master thesis",
  language  = "en"
}
